  !! Note: In reference implementation, W_embedding is implemented as an Embedding layer.
  !!       Notice that this means the input to the model is instantiated as a vector of
  !!       indices, rather than a high-dimensional sparse vector.
  !! Note: For this log, we do not shuffle the training data, so the "model input" printed
  !!       below corresponds to the preprocessing of the first `batch_size` records in the dataset.
==================================================
START ONE ITERATION OF TRAINING
batch number: 0
model input: (shape=(256, 1069))
[[    0     0     0     0     0     0     0     0     0     0 ...   370   377   420   466   480   539   586   588   589   616]
 [    0     0     0     0     0     0     0     0     0     0 ...   648   719   733   736   780   786   802  1049  1351  1528]
 [    0     0     0     0     0     0     0     0     0     0 ...  4958  5262  5468  5490  6330  6489  7101  7103  7965  8192]
 [    0     0     0     0     0     0     0     0     0     0 ...   420   432   434   435   440   480   586   587   588   589]
 [    0     0     0     0     0     0     0     0     0     0 ...  1216  1222  1227  1241  1244  1255  1277  1291  1296  1386]
 [    0     0     0     0     0     0     0     0     0     0 ...  3705  3718  3720  3827  3957  3959  4124  4233  4332  4409]
 [    0     0     0     0     0     0     0     0     0     0 ...  5255  5258  5403  5444  5463  5465  5468  5491  5789  6233]
 [    0     0     0     0     0     0     0     0     0     0 ...  8279  8283  8348  8356  8370  8377  8381  8394  9737 10308]
 [    0     0     0     0     0     0     0     0     0     0 ...  2764  2825  3394  3861  3997  4189  5257  7309  8585  9588]
 [    0     0     0     0     0     0     0     0     0     0 ...  2701  2712  2819  2839  2884  2905  2910  2954  3034  3035]
 ...
 [    0     0     0     0     0     0     0     0     0     0 ...  8210  8326  8370  8543  8646  9862  9973 10018 10476 10655]
 [    0     0     0     0     0     0     0     0     0     0 ...  8432  8526  8543  8804  8834  9973 10312 10416 10520 10655]
 [    0     0     0     0     0     0     0     0     0     0 ...   480   500   539   551   553   586   588   589   592   597]
 [    0     0     0     0     0     0     0     0     0     0 ...  3720  3827  3843  3966  3981  3982  3988  4003  4004  4030]
 [    0     0     0     0     0     0     0     0     0     0 ...  4686  4942  4998  5312  5315  5340  5341  5345  5355  5373]
 [    0     0     0     0     0     0     0     0     0     0 ...  9225  9228  9239  9267  9311  9367 10010 10288 10303 10537]
 [    0     0     0     0     0     0     0     0     0     0 ...   532   539   540   587   589   590   595   597   648   653]
 [    0     0     0     0     0     0     0     0     0     0 ...   648   708   736   761   780   783   786  1073  1351  1354]
 [    0     0     0     0     0     0     0     0     0     0 ...   733   762   780   784   786   788   805   858  1073  1388]
 [    0     0     0     0     0     0     0     0     0     0 ...  1657  1756  1801  1844  1979  2255  2256  2265  2321  2375]]
 
model target: (shape=(256, 10678))
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 1. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 ...
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ... 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]
 
==========
START FORWARD PASS
Shape of input:                                torch.Size([256, 1069])
Shape of Linear(num_toks -> emb_dim) output:   torch.Size([256, 800])
Shape of Dropout(0.5) output:                  torch.Size([256, 800])
Shape of Linear(emb_dim -> hidden_dim) output: torch.Size([256, 400])
Shape of Dropout(0.5) output:                  torch.Size([256, 400])
Shape of output:                               torch.Size([256, 10678])
==========
FINISH FORWARD PASS
==================================================
FINISH ONE ITERATION OF TRAINING
